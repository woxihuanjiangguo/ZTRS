# Inference
We provide inference scripts for the Navhard benchmark. Please generate the metric cache first for Navhard according to [cache.md](cache.md).

The inference process of GTRS consists of two stages:
1. Trajectory Generation: The Diffusion Policy generates N candidate trajectories (typically N = 100) for each scene in the Navhard benchmark.
2. Trajectory Scoring: A GTRS scorer variant evaluates the N trajectories and its vocabulary to select the final output.


## Format checkpoints
Before evaluation, the checkpoints in the training directory should be renamed. This step can be skipped if you use our provided checkpoints.

```bash
dir=your_path_to_exp # e.g. train_dp
cd ${NAVSIM_EXP_ROOT}/${dir}
for file in epoch=*-step=*.ckpt; do
    epoch=$(echo $file | sed -n 's/.*epoch=\([0-9][0-9]\).*/\1/p')
    new_filename="epoch${epoch}.ckpt"
    mv "$file" "$new_filename"
done
```
## Diffusion Policy
The script loads a trained Diffusion Policy model and generates multiple trajectory proposals for each scene. From the 
N generated trajectories, one is randomly selected to serve as the final inference result for that scene.
```bash
export PROGRESS_MODE="eval"
split=navhard
agent=gtrs_diffusion_policy
dir=train_dp
metric_cache_path="${NAVSIM_EXP_ROOT}/${split}_two_stage_metric_cache"
cd ${NAVSIM_DEVKIT_ROOT}

for epoch in 49; do
    padded_epoch=$(printf "%02d" $epoch)
    experiment_name="${dir}/test-${padded_epoch}ep-${split}-random"
    ckpt=${NAVSIM_EXP_ROOT}/${dir}/epoch${padded_epoch}.ckpt # this can also be the checkpoint we provided
    export DP_PREDS=none
    export SUBSCORE_PATH=${NAVSIM_EXP_ROOT}/${dir}/epoch${epoch}_${split}.pkl # save path for the dp-generated trajectories

    python ${NAVSIM_DEVKIT_ROOT}/navsim/planning/script/run_pdm_score_gpu_v2.py \
        agent=$agent \
        dataloader.params.batch_size=32 \
        agent.checkpoint_path=${ckpt} \
        trainer.params.precision=32 \
        experiment_name=${experiment_name} \
        +cache_path=null \
        metric_cache_path=${metric_cache_path} \
        train_test_split=${split}_two_stage
done
```

## GTRS-Dense
After generating the trajectories with DP, we can perform inference using GTRS-Dense. Note that we use the smaller vocabulary (8192) for inference:
```bash
export PROGRESS_MODE="eval"
split=navhard
agent=gtrs_dense_vov
dir=train_gtrs_dense
metric_cache_path="${NAVSIM_EXP_ROOT}/${split}_two_stage_metric_cache"
cd ${NAVSIM_DEVKIT_ROOT}

for epoch in 19; do
    padded_epoch=$(printf "%02d" $epoch)
    experiment_name="${dir}/test-${padded_epoch}ep-${split}-random"
    ckpt=${NAVSIM_EXP_ROOT}/${dir}/epoch${padded_epoch}.ckpt # this can also be the checkpoint we provided
    
    export DP_PREDS=${NAVSIM_EXP_ROOT}/train_dp/epoch49_${split}.pkl # this is generated by the previous step
    export SUBSCORE_PATH=${NAVSIM_EXP_ROOT}/${dir}/epoch${epoch}_${split}.pkl; # save path for the scores

    python ${NAVSIM_DEVKIT_ROOT}/navsim/planning/script/run_pdm_score_gpu_v2.py \
        agent=$agent \
        +combined_inference=true \
        dataloader.params.batch_size=32 \
        agent.checkpoint_path=${ckpt} \
        agent.config.vocab_path=${NAVSIM_DEVKIT_ROOT}/traj_final/8192.npy \
        trainer.params.precision=32 \
        experiment_name=${experiment_name} \
        +cache_path=null \
        metric_cache_path=${metric_cache_path} \
        train_test_split=${split}_two_stage
done
```

## GTRS-Aug
Similarly, GTRS-Aug also utilizes the trajectories generated by DP for inference. 
For the Navhard Benchmark, we find that using the trajectories output before the Refinement Decoder yields the best result, which is slightly different from the findings on the Navtest Benchmark (see [DriveSuprim](https://www.arxiv.org/pdf/2506.06659)).
```bash
export PROGRESS_MODE="eval"
split=navhard
agent=gtrs_aug_vov
dir=train_gtrs_aug
metric_cache_path="${NAVSIM_EXP_ROOT}/${split}_two_stage_metric_cache"
cd ${NAVSIM_DEVKIT_ROOT}

for epoch in 5; do
    padded_epoch=$(printf "%02d" $epoch)
    experiment_name="${dir}/test-${padded_epoch}ep-${split}-random"
    ckpt=${NAVSIM_EXP_ROOT}/${dir}/epoch${padded_epoch}.ckpt # this can also be the checkpoint we provided
    
    export DP_PREDS=${NAVSIM_EXP_ROOT}/train_dp/epoch49_${split}.pkl # this is generated by the previous step
    export SUBSCORE_PATH=${NAVSIM_EXP_ROOT}/${dir}/epoch${epoch}_${split}.pkl; # save path for the scores

    python ${NAVSIM_DEVKIT_ROOT}/navsim/planning/script/run_pdm_score_gpu_v2_aug.py \
        agent=$agent \
        +combined_inference=true \
        dataloader.params.batch_size=32 \
        agent.checkpoint_path=${ckpt} \
        agent.config.training=false \
        agent.config.only_ori_input=true \
        agent.config.inference.model=teacher \
        agent.config.lab.use_first_stage_traj_in_infer=true \
        trainer.params.precision=32 \
        experiment_name=${experiment_name} \
        +cache_path=null \
        metric_cache_path=${metric_cache_path} \
        train_test_split=${split}_two_stage
done
```


## Hydra-MDP
To perform inference without using diffusion policy-generated trajectories, use the script below. 
This is equivalent to [Hydra-MDP](https://arxiv.org/abs/2406.06978) (img-only, vocabulary size 16384).
```bash
export PROGRESS_MODE="eval"
split=navhard
agent=hydra_mdp_vov
dir=train_hydra_mdp
metric_cache_path="${NAVSIM_EXP_ROOT}/${split}_two_stage_metric_cache"
cd ${NAVSIM_DEVKIT_ROOT}

for epoch in 19; do
    padded_epoch=$(printf "%02d" $epoch)
    experiment_name="${dir}/test-${padded_epoch}ep-${split}-random"
    ckpt=${NAVSIM_EXP_ROOT}/${dir}/epoch${padded_epoch}.ckpt # this can also be the checkpoint we provided
    
    export DP_PREDS=None
    export SUBSCORE_PATH=${NAVSIM_EXP_ROOT}/${dir}/epoch${epoch}_${split}.pkl; # save path for the scores

    python ${NAVSIM_DEVKIT_ROOT}/navsim/planning/script/run_pdm_score_gpu_v2.py \
        agent=$agent \
        +combined_inference=false \
        dataloader.params.batch_size=32 \
        agent.checkpoint_path=${ckpt} \
        agent.config.vocab_path=${NAVSIM_DEVKIT_ROOT}/traj_final/16384.npy \
        trainer.params.precision=32 \
        experiment_name=${experiment_name} \
        +cache_path=null \
        metric_cache_path=${metric_cache_path} \
        train_test_split=${split}_two_stage
done
```
